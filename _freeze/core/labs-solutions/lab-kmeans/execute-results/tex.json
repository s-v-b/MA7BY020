{
  "hash": "442cec2e3ffb64acf853aefc8a8f87e5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab: Clustering k-means\"\ndate: \"2026-01-11 22:20:12.792433\"\n\nexecute:\n  echo: true\n  eval: true\n  collapse: true\n  message: false\n  warning: false\n\nformat:\n  html:\n    output-file: lab-kmeans.html\n  pdf:\n    output-file: lab-kmeans.pdf\n\nengine: knitr\n---\n\n\n\n\n::: {layout=\"[80,20]\"}\n\n::: {#first-column}\n\n|                            |\n|:---------------------------|\n| {{< var curriculum >}}     |\n| {{< var university >}}     |\n| Année {{< var year >}}     |\n| {{< var homepage >}}       |\n| {{< var moodle >}}         |\n\n\n::: \n\n::: {#second-column}\n![](/images/UniversiteParis_monogramme_couleur_RVB.png){align=\"right\" style=\"size:50px;\" width=75}\n:::\n\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nstopifnot(\n  require(gt),\n  require(sloop),\n  require(lobstr), \n  require(skimr),\n  require(GGally),\n  require(patchwork),\n  require(ggforce),\n  require(glue),\n  require(ggfortify),\n  require(ggvoronoi),\n  require(magrittr),\n  require(broom),\n  require(tidyclust),\n  require(tidyverse)\n)\n\ntidymodels::tidymodels_prefer(quiet = TRUE)\n\nold_theme <-theme_set(\n  theme_minimal(base_size=9, \n                base_family = \"Helvetica\")\n)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nknitr::opts_chunk$set(\n  message = FALSE,\n  warning = FALSE,\n  comment=NA,\n  prompt=FALSE,\n  cache=FALSE,\n  echo=TRUE,\n  results='asis'\n)\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ngc <- options(ggplot2.discrete.colour=\"viridis\")\ngc <- options(ggplot2.discrete.fill=\"viridis\")\ngc <- options(ggplot2.continuous.fill=\"viridis\")\ngc <- options(ggplot2.continuous.colour=\"viridis\")\n```\n:::\n\n\nForeword\n--------\n\n\nThis lab is dedicated to the *k-means* clustering method. In words, *k-means* takes as input a collection of points in $\\mathbb{R}^d$ (a numerical dataset) and a positive integer $k$. It returns  a collection of $k$ points (the *centers*) from $\\mathbb{R}^d$. The centers define a Voronoï *tesselation*/*partition*/*diagran* of $\\mathbb{R}^d$. The Voronoï *cells* define a clustering of the original dataset.\n\n\nVoronoi tesselation/partition/diagram\n--------------------------------------\n\n[Wikipedia on Voronoï diagrams](https://en.wikipedia.org/wiki/Voronoi_diagram)\n\nIn the next chunk, we generate a Voronoï diagram on $\\mathbb{R}^2$ with $100$ cells defined from $100$ random points drawn from the uniform distribution on a square. \nFunction `stat_voronoi()` comes from [ggvoronoi](https://github.com/garretrc/ggvoronoi) \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(45056)\n\npoints <- tibble(\n  x=runif(100, 0, 1),\n  y=runif(100, 0, 1),\n  distance = sqrt((x-100)^2 + (y-100)^2)\n) \n\np <- ggplot(points) +\n    aes(x=x, y=y) +\n    geom_point(size=.2) +\n    coord_fixed() +\n    xlim(c(-.25, 2.25)) +\n    ylim(c(-.25, 2.25)) \n\np + (p + stat_voronoi(geom=\"path\")) +\n  patchwork::plot_annotation(\n    title=\"Voronoi tesselation\",\n    subtitle = \"Left: 100 random points\\nRight: Voronoï diagram\")\n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/voronoi-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n::: {.callout-note}\n\n- Two adjacent Voronoï cells are separated by a (possibly semi-infinite)  line segment\n- Let the so-called *centers* be denoted by  $c_1, \\ldots, c_n$. They form the *codebook* $\\mathcal{C}$.  \n- The Voronoï cell with *center*  $c_i$ is defined by \n$$\\left\\{x : x \\in \\mathbb{R}^d, \\qquad \\| x- c_i \\|_2 = \\min_{j \\leq n} \\|x -c_j\\|_2\\right\\}$$\n- The center of a Voronoï cell is usually not its barycenter\n\n:::\n\n_k_-means objective function\n----------------------------\n\n\n\n::: {.callout-note}\n\n### Definition\n\nThe $k$-means algorithm aims at building a _codebook_ $\\mathcal{C}$ that minimizes\n\n$$\\mathcal{C} \\mapsto \\sum_{i=1}^n \\min_{c \\in \\mathcal{C}}  \\Vert X_i - c\\Vert_2^2$$\n\nover all codebooks with given cardinality\n\nIf $c \\in \\mathcal{C}$ is the closest centroid to $X \\in \\mathbb{R}^p$,\n\n$$\\|c - X\\|^2$$ \n\nis the _quantization/reconstruction error_ suffered when using codebook $\\mathcal{C}$ to approximate $X$\n\n:::\n\n::: {.callout-caution}\n\n{{< fa exclamation-triangle >}} If there are no restrictions on the dimension of the input space, on the number of centroids, or on sample size, computing an optimal codebook is a $\\mathsf{NP}$ -hard problem\n\n\n:::\n\nThe `kmeans()` function\n-----------------------------\n\n\n\n\n`kmeans()` is a wrapper for a collection of Algorithms that \nlook like the Lloyd algorithm\n\n\nInitialize \n: Choose $k$ centroids\n\nIterations: Two phases\n\nMovement \n: Assign each sample point to the closest centroid (Assign each sample point to a class in the Voronoi partition defined by the centroids)\n\nUpdate \n: For each class in the current Voronoi partition, update the centroid so as to minimize the *Within Cluster Sum of Squared distances*.\n\n\n\n{{< fa hand-point-right >}} No guarantee to converge to a global optimum!\n\nProceeed by trial and error.\n\nRepeat the algorithm and keep the best result.\n\n\n\nIris data \n----------\n\n::: {.callout-note title='Question'} \n \nRun `kmeans()` on the projection of the Iris dataset  (`data(iris)`) on the `Petal` plane.\n\nCheck `?iris` and [https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set) for more on this (historical) dataset. \n\n\n:::\n\n::: {.content-visible when-profile='solution'} \n \n::: {.callout-tip title='Solution'} \n \nWe look for a partition into three cells.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(iris)\n\nkms <- iris |> \n  select(starts_with(\"Petal\")) |>\n  kmeans(3)\n\nclass(kms)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"kmeans\"\n```\n\n\n:::\n\n```{.r .cell-code}\nsloop::otype(kms)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"S3\"\n```\n\n\n:::\n:::\n\n\nThe result is an object of class `kmeans`. The class is equiped with `broom` methods.  \n\n::: \n:::\n\n\n::: {.callout-note title='Question'} \n\n- Check the *attributes* of object `kms`\n- Unclass the object and check the attributes again.\n \n:::\n\n::: {.content-visible when-profile='solution'} \n \n::: {.callout-tip title='Solution'} \n \n\n::: {.cell}\n\n```{.r .cell-code}\nattributes(kms)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$names\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n$class\n[1] \"kmeans\"\n```\n\n\n:::\n\n```{.r .cell-code}\nukms <- unclass(kms)\nattributes(ukms)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$names\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n```\n\n\n:::\n\n```{.r .cell-code}\nclass(kms)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"kmeans\"\n```\n\n\n:::\n\n```{.r .cell-code}\nkms_bornagain <- structure(\n  ukms, \n  class=\"kmeans\")\n\nsloop::otype(kms_bornagain)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"S3\"\n```\n\n\n:::\n\n```{.r .cell-code}\nclass(kms_bornagain)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"kmeans\"\n```\n\n\n:::\n:::\n\n \nObjects of class `kmeans` have two attributes `names`  and `class`. Because of the `class` attribute, objects of class `kmeans`  are not just lists with named elements.   \n\n\n::: \n \n:::\n\nSummarizing a clustering \n-------------------------\n\n::: {.callout-note title=\"Question\"}\n\nCheck the structure of objects of class `kmeans` and use `broom::tidy()` to get a summary. \n\nCompare with `summary()` from base `R`\n\n:::\n\n::::: {.content-visible when-profile=\"solution\"}  \n\n::: {.callout-tip title='Solution'} \n \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_centers <- select(iris, starts_with(\"Petal\")) |>\n  kmeans(centers = 3) |> \n  broom::tidy() \n\ndf_centers |>  \n  gt::gt() |>\n  gt::fmt_number(decimals = 2) |>\n  gt::tab_caption(\"Iris clustering in the Petal plane, kmeans with 3 clusters\")\n```\n\n::: {.cell-output-display}\n\\begingroup\n\\fontsize{12.0pt}{14.4pt}\\selectfont\n\\begin{longtable}{rrrrc}\n\\toprule\nPetal.Length & Petal.Width & size & withinss & cluster \\\\ \n\\midrule\\addlinespace[2.5pt]\n4.27 & 1.34 & 52.00 & 13.06 & 1 \\\\ \n1.46 & 0.25 & 50.00 & 2.02 & 2 \\\\ \n5.60 & 2.04 & 48.00 & 16.29 & 3 \\\\ \n\\bottomrule\n\\end{longtable}\n\\endgroup\n\n:::\n:::\n\n\n- How are the rows related to clusters?\n- What are the coordinates good for?\n- What does the `size` column mean?\n- `withinss` stands for *Within Sum of Squares*. How is it computed? Why is it useful?\n\n:::\n\n:::::\n\n\nVisualizing a clustering\n-------------------------\n\n::: {.callout-note  title=\"Question\"}\n\nUse `broom::augment()` and `broom::tidy()` to prepare two dataframes that will allow you to overlay a scatterplot of the dataset and a Voronoï diagram defined by the centers output by `kmeans()`. \n\nCompare the result with `plot()`\n\n:::\n\n::::: {.content-visible when-profile=\"solution\"}  \n\n::: {.callout-tip title='Solution'} \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- kms |> \n  augment(iris) |>\n  ggplot() +\n  aes(x=Petal.Length, \n      y=Petal.Width\n      ) +\n  geom_point(aes(shape=Species), size=1, show.legend = F) +\n  coord_fixed()\n\nqq <-  (q + geom_point(aes(shape=Species, \n                           colour=.cluster), \n                       size=1))+\n  stat_voronoi(data = df_centers,   #<<\n               geom=\"path\",\n               outline=data.frame(x=c(0, 7, 7, 0), \n                                  y=c(0, 0, 3, 3))\n               ) +\n  geom_point(data = df_centers,   #<<\n             colour = \"black\",\n             shape=\"+\",\n             size=5)  \n\nq / qq +\n  plot_annotation(title = \"Kmeans over Iris dataset, k=3\")\n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/unnamed-chunk-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n:::\n\n\n::: {.callout-tip title='Solution'} \n \n \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngeom_sugar <- list(\n    stat_voronoi(data = df_centers,\n                 geom=\"path\",\n                 alpha=.5,\n                 outline = tribble(~x, ~y,\n                                   0., 0.,\n                                   7., 0.,\n                                   7., 3,\n                                   0., 3) \n                 ),\n    geom_point(data = df_centers,   \n               colour = \"black\",\n               shape=\"+\",\n               size=5),\n    coord_fixed(),\n    labs(col=\"Voronoï cells\")\n)\n```\n:::\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbroom::augment(kms, iris) |>\n  ggplot(aes(x=Petal.Length, y=Petal.Width)) +\n  geom_point(aes(shape=Species, color=.cluster)) +\n  geom_sugar \n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/unnamed-chunk-7-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n:::\n\n::: {.callout-tip title='Solution'} \n \n\n::: {.cell}\n\n```{.r .cell-code}\nkms |> \n  autoplot(data=iris)\n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/unnamed-chunk-8-1.pdf){fig-pos='H'}\n:::\n:::\n\n:::\n\n:::::\n\n::: {.callout-note title=\"Question\"}\n\nRedo the same operations but choose the `Sepal.xxx` dimension.\n\nDesign a function to avoid repetitive coding.  \n\n:::\n\n::::: {.content-visible when-profile=\"solution\"}  \n\n::: {.callout-tip title='Solution'} \n \n\n::: {.cell}\n\n```{.r .cell-code}\nplot_km_centroids <- function(augmented_km, centroids, col1, col2){\n\n  outline <- augmented_km |>\n    dplyr::select({{col1}}, {{col2}}) |>\n    dplyr::rename(x={{col1}}, y={{col2}}) |> \n    summarise(across(everything(), .fns=list(\"min\"= min, \"max\"=max), .names=\"{.col}_{.fn}\"))\n\n  tb_outline <- tibble(\n    x = with(outline, c(x_min-1.0, x_max+1.0, x_max+1.0, x_min-1.0)),\n    y = with(outline, rep(c(y_min-1, y_max+1), each=2)),\n    group=rep(1, 4)\n  )\n\n  p <- augmented_km |> \n  ggplot() +\n  aes(\n    x={{col1}}, \n    y={{col2}}) +\n  geom_point(aes(colour=.cluster))  +\n  stat_voronoi(data = centroids,\n               geom=\"path\",\n               outline= tb_outline\n  ) +\n  geom_point(data = centroids,\n             colour = \"black\",\n             shape=\"+\",\n             size=5) +\n  coord_fixed() +\n  theme_minimal()\n\n  if (has_rownames(augmented_km)) {\n    p <- p +\n      ggrepel::geom_label_repel(\n        aes(colour=.cluster, \n            label=`.rownames`))\n  }\n\n  return(p)\n}\n```\n:::\n\n\n \n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkms <- kmeans(select(iris, Sepal.Length, Sepal.Width), 3)\n\n\nplot_km_centroids(\n  augment(kms, iris), \n  tidy(kms), \n  Sepal.Length, \n  Sepal.Width\n)\n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/iriskmeans3-1.pdf){fig-pos='H'}\n:::\n:::\n\n:::::\n\n\nPlaying with $k$ \n-----------------\n\nThe number of cells/clusters may not be given a priori. Conducting clustering using \na method like `kmeans` requires picking a reasonable choice for `k`. \n\n::: {.callout-note}\n\n### Question\n\nPerform kmeans clustering with $k=2$.  Use `glance`, `tidy`, `augment` to discuss the result.\n\n:::\n\n\n::::: {.content-visible when-profile=\"solution\"}  \n\n::: {.callout-tip title='Solution'} \n \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- select(iris, \n             starts_with(\"Sepal\"))\n\nkms <- kmeans(df, 2)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_km_centroids(\n  augment(kms, iris),\n  tidy(kms),\n  Sepal.Length,\n  Sepal.Width\n)\n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/iriskmeans2bis-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nWe can compare the spread between inner and outer sum of squares for clusterings \nwith $k \\in 2, 3$. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_rows(glance(kms),\n          glance(kmeans(df, centers=3,\n              nstart = 32L))) |> \n  mutate(k=c(2, 3))  |>\n  gt::gt()\n```\n\n::: {.cell-output-display}\n\\begingroup\n\\fontsize{12.0pt}{14.4pt}\\selectfont\n\\begin{longtable}{rrrrr}\n\\toprule\ntotss & tot.withinss & betweenss & iter & k \\\\ \n\\midrule\\addlinespace[2.5pt]\n130.4753 & 58.44759 & 72.02767 & 1 & 2 \\\\ \n130.4753 & 37.05070 & 93.42456 & 3 & 3 \\\\ \n\\bottomrule\n\\end{longtable}\n\\endgroup\n\n:::\n:::\n\n \n:::\n\n:::::\n\n::: {.callout-note}\n\n### Question\n\nPerform k-means for $k=2, ... 10$, plot within sum of squares as function of $k$. \nComment. \n\n:::\n\n\n\n::::: {.content-visible when-profile=\"solution\"}  \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmp <-map_dfr(2:10, ~ glance(kmeans(df, \n                                   centers=.,\n                                   nstart = 32L))) |> \n  rowid_to_column(var=\"k\") |> \n  mutate(k=k+1, across(where(is.numeric), ~ signif(.x, 3))) \n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmp |>\n  ggplot(aes(x=forcats::as_factor(k), y=tot.withinss/totss)) +\n  geom_col(width=.25) +\n  ggtitle(\"Iris data\", \"WithinSS/Total Sum of Squares as a function of k\") +\n  xlab(\"k\") +\n  ylab(\"Within Clusters Sum of Squares (relative)\") +\n  scale_x_discrete(breaks=as.character(2:10), labels=as.character(2:10))\n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/iriswithinss-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkms <- kmeans(df, 4)\niris4 <- broom::augment(kms, iris)\n\n\nplot_km_centroids(\n  augment(kms, iris),\n  tidy(kms),\n  Sepal.Length,\n  Sepal.Width\n)  +\n ggtitle(label=\"Kmeans Iris data\",\n         subtitle=\"k=4\") +\n labs(col=\"Clusters\")\n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/iriskmeans4-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbroom::tidy(kmeans(df, 4)) |>\n  gt::gt() |>\n  gt::fmt_number(decimals = 2)\n```\n\n::: {.cell-output-display}\n\\begingroup\n\\fontsize{12.0pt}{14.4pt}\\selectfont\n\\begin{longtable}{rrrrc}\n\\toprule\nSepal.Length & Sepal.Width & size & withinss & cluster \\\\ \n\\midrule\\addlinespace[2.5pt]\n7.28 & 3.13 & 18.00 & 3.91 & 1 \\\\ \n6.35 & 2.94 & 50.00 & 6.79 & 2 \\\\ \n5.52 & 2.61 & 33.00 & 5.97 & 3 \\\\ \n5.02 & 3.45 & 49.00 & 11.57 & 4 \\\\ \n\\bottomrule\n\\end{longtable}\n\\endgroup\n\n:::\n:::\n\n\n\n:::::   \n\n\nLloyd's iterations \n---------------------\n\nThe `kmeans` function does not minimize the `kmeans` cost. It offers a collection \nof iterative algorithms that aim at approximately minimizing the cost. \n\n\n::: {.callout-note}\n\nInitialize \n: Choose $k$ centroids\n\nIterations: Two phases\n\nMovement \n: Assign each sample point to the closest centroid (Assign each sample point to a class in the Voronoi partition defined by the centroids)\n\nUpdate \n: For each class in the current Voronoi partition, update the centroid so as to minimize the *Within Cluster Sum of Squared distances*.\n\n\n:::\n\n\n::::: {.content-visible when-profile=\"solution\"}  \n\n::: {.callout-tip title='Solution'} \n \n \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkm <- list(centers=df[1:3, ]) # stupid initialization\n\nsequence <- list()\n\nfor (i in 1:20) {\n  km <- kmeans(df,\n               km$centers,\n               algorithm = \"Lloyd\",\n               iter.max = 1)\n  sequence[[length(sequence)+1]] <- force(km)\n}\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadd_voronoi <- function(p, kmscenters, marker){\n  p +\n    geom_point(data=data.frame(kmscenters),         #<<\n               mapping=aes(x=Sepal.Length, y=Sepal.Width),\n               shape=marker,\n               col=\"black\",\n               size=5) +\n    stat_voronoi(data = as.data.frame(kmscenters),  #<<\n                 aes(x=Sepal.Length,y=Sepal.Width),\n                 geom=\"path\",\n                 outline=data.frame(x=c(4, 8, 8, 4),\n                                    y=c(2, 2, 4.5, 4.5)))\n}\n```\n:::\n\n:::\n\n::: {.callout-tip title='Solution'} \n \n \n\n\n::: {.cell}\n\n```{.r .cell-code}\ni <- 2\n\np <- broom::augment(sequence[[i]], iris) |>\n  ggplot() +\n  coord_fixed(ratio=1) +\n  geom_point(aes(x=Sepal.Length, y=Sepal.Width, shape=Species, col=.cluster)) +\n  ggtitle(\"Kmeans Lloyd's algorithm\", \"Iris data\")\n\np |>\n  add_voronoi(sequence[[i]]$centers, marker=\"o\") +   #<<\n  labs(colour=paste(\"Cluster, step \", i- 1))\n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/lloyd1-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ni <- 2\n\n(p %+%\n  broom::augment(sequence[[i]], iris)) |>\n  add_voronoi(sequence[[i]]$centers, marker='+') +   #<<\n  geom_point(data=data.frame(sequence[[2]]$centers),   #<<\n             mapping=aes(x=Sepal.Length, y=Sepal.Width),\n             shape=\"o\", col=\"black\", size=5) +\n  labs(colour=paste(\"Cluster, step \", i- 1))\n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/unnamed-chunk-15-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n:::\n\n::: {.callout-tip title='Solution'} \n \n\n\n::: {.cell}\n\n```{.r .cell-code}\ni <- 3\n\n(p %+%\n  broom::augment(sequence[[i]], iris)) |>\n  add_voronoi(sequence[[i]]$centers, marker='+') +   #<<\n  geom_point(data=data.frame(sequence[[2]]$centers),   #<<\n             mapping=aes(x=Sepal.Length, y=Sepal.Width),\n             shape=\"o\", col=\"black\", size=5) +\n  labs(colour=paste(\"Cluster, step \", i- 1))\n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/lloyd5-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ni <- 5\n\n(p %+%\n  broom::augment(sequence[[i]], iris)) |>\n  add_voronoi(sequence[[i]]$centers, marker='*') +   #<<\n  geom_point(data=data.frame(sequence[[2]]$centers),   #<<\n             mapping=aes(x=Sepal.Length, y=Sepal.Width),\n             shape=\"o\", col=\"black\",size=5) +\n  labs(colour=paste(\"Cluster, step \", i- 1))\n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/lloyd00-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n:::\n\n:::::\n\n\nRevisiting the `swiss` fertility data\n-------------------------------------\n\n::: {.callout-note title='Question'} \n \nRecall the dataset used in [Lab PCA](/core/labs/lab-pca.qmd)\n\nPerform kmeans clustering in original coordinates and kmeans clustering in the first principal coordinates plane \n\nCompare the results\n\n:::\n\n\n::: {.content-visible when-profile=\"solution\"} \n::: {.callout-tip title=\"solution\"} \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(swiss)\n\nswiss_scaled <- swiss |>  \n  select(-Fertility) |> \n  scale() \n\nkm.2.swiss <- swiss_scaled |> \n  kmeans(centers = 2,  nstart = 10L)\n\ndf_centers.2 <- broom::tidy(km.2.swiss)\n```\n:::\n\n\n\n:::\n\n::: {.callout-tip title=\"solution\"} \n\n\n::: {.cell}\n\n```{.r .cell-code}\nkm.2.swiss.pca <-  swiss_scaled |>\n  prcomp() |> \n  augment(data=swiss)|> \n  dplyr::select(starts_with(\".fittedPC\")) |> \n  kmeans(centers=2, nstart = 10L)\n\ndf_centers.2.pca <- tidy(km.2.swiss.pca)\n```\n:::\n\n\n:::\n\n::: {.callout-tip title='Solution'} \n \n::: {.columns}\n::: {.column}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_centers.2 |>\n  gt::gt() |> \n  gt::fmt_number(decimals = 2)\n```\n\n::: {.cell-output-display}\n\\begingroup\n\\fontsize{12.0pt}{14.4pt}\\selectfont\n\\begin{longtable}{rrrrrrrc}\n\\toprule\nAgriculture & Examination & Education & Catholic & Infant.Mortality & size & withinss & cluster \\\\ \n\\midrule\\addlinespace[2.5pt]\n0.68 & -0.83 & -0.53 & 0.99 & 0.25 & 19.00 & 49.26 & 1 \\\\ \n-0.46 & 0.57 & 0.36 & -0.67 & -0.17 & 28.00 & 101.66 & 2 \\\\ \n\\bottomrule\n\\end{longtable}\n\\endgroup\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkm.2.swiss |> \n  broom::glance() |>\n  gt::gt() |> \n  gt::fmt_number(decimals = 2)\n```\n\n::: {.cell-output-display}\n\\begingroup\n\\fontsize{12.0pt}{14.4pt}\\selectfont\n\\begin{longtable}{rrrr}\n\\toprule\ntotss & tot.withinss & betweenss & iter \\\\ \n\\midrule\\addlinespace[2.5pt]\n230.00 & 150.91 & 79.09 & 1.00 \\\\ \n\\bottomrule\n\\end{longtable}\n\\endgroup\n\n:::\n:::\n\n\n:::\n\n::: {.column}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_centers.2.pca |>\n  gt::gt() |> \n  gt::fmt_number(decimals = 2)\n```\n\n::: {.cell-output-display}\n\\begingroup\n\\fontsize{12.0pt}{14.4pt}\\selectfont\n\\begin{longtable}{rrrrrrrc}\n\\toprule\n.fittedPC1 & .fittedPC2 & .fittedPC3 & .fittedPC4 & .fittedPC5 & size & withinss & cluster \\\\ \n\\midrule\\addlinespace[2.5pt]\n-1.02 & -0.21 & 0.25 & 0.02 & 0.05 & 28.00 & 101.66 & 1 \\\\ \n1.50 & 0.32 & -0.36 & -0.02 & -0.07 & 19.00 & 49.26 & 2 \\\\ \n\\bottomrule\n\\end{longtable}\n\\endgroup\n\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkm.2.swiss.pca |> \n  broom::glance() |>\n  gt::gt() |> \n  gt::fmt_number(decimals = 2)\n```\n\n::: {.cell-output-display}\n\\begingroup\n\\fontsize{12.0pt}{14.4pt}\\selectfont\n\\begin{longtable}{rrrr}\n\\toprule\ntotss & tot.withinss & betweenss & iter \\\\ \n\\midrule\\addlinespace[2.5pt]\n230.00 & 150.91 & 79.09 & 1.00 \\\\ \n\\bottomrule\n\\end{longtable}\n\\endgroup\n\n:::\n:::\n\n:::\n:::  \n \n:::\n\n::: {.callout-tip title=\"solution\"} \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_km_centroids(\n  broom::augment(km.2.swiss, scale(swiss)),\n  broom::tidy(km.2.swiss), \n  Education, \n  Infant.Mortality\n) +\n  labs(\n    title= \"Kmeans over Swiss dataset, k=2\"\n  ) \n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/kmeans-swiss-individuals-1.pdf){fig-pos='H'}\n:::\n:::\n\n:::\n\n::: {.callout-tip title='Solution'} \n \n\n::: {.cell}\n\n```{.r .cell-code}\nplot_km_centroids(\n  augment(km.2.swiss.pca,\n         broom::augment(prcomp(swiss_scaled), data=swiss)),\n  tidy(km.2.swiss.pca),\n  .fittedPC1,\n  .fittedPC2\n) + labs(\n      title=\"Kmeans over Swiss dataset, k=2\",\n      subtitle=\"Clustering over the Principal components\"\n  ) \n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/kmeans-swiss-individuals-pca-1.pdf){fig-pos='H'}\n:::\n:::\n\n:::\n:::\n\n\n::: {.content-visible when-profile='solution'} \n \n::: {.callout-tip title='Solution'} \n \n\n::: {.cell}\n\n```{.r .cell-code}\nkm.4.swiss.pca <-  swiss_scaled |>\n  prcomp() |> \n  broom::augment(data=swiss)|> \n  dplyr::select(starts_with(\".fittedPC\")) |> \n  kmeans(centers=4, nstart = 10L)\n\ndf_centers.4.pca <- broom::tidy(km.4.swiss.pca)\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_km_centroids(\n  augment(km.4.swiss.pca,\n         broom::augment(prcomp(swiss_scaled), data=swiss)),\n  tidy(km.4.swiss.pca),\n  .fittedPC1,\n  .fittedPC2\n) + labs(\n      title=\"Kmeans over Swiss dataset, k=4\",\n      subtitle=\"Clustering over the Principal components\"\n  ) \n```\n\n::: {.cell-output-display}\n![](lab-kmeans_files/figure-pdf/unnamed-chunk-23-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n::: \n:::\n\nRevisiting the `mortality` dataset \n-----------------------------------\n\n::: {.callout-note title='Question'} \n \nRecall the dataset used in [Lab CA](/core/labs/lab-ca-mortality.qmd)\n\nPerform kmeans clustering of categories in the row principal coordinates \nand the column principal coordinates \n\n:::\n\n\n::: {.content-visible when-profile='solution'} \n \n \n:::\n\n\n\n\n\n\nReferences\n----------\n\n[Vignette `k_means` from `tidyclust`](https://tidyclust.tidymodels.org/articles/k_means.html)\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\n\\usepackage{caption}\n\\usepackage{longtable}\n\\usepackage{colortbl}\n\\usepackage{array}\n\\usepackage{anyfontsize}\n\\usepackage{multirow}\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}