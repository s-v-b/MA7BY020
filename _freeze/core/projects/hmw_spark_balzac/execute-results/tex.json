{
  "hash": "da758d962a7cb42c847b378e032f6a5c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hmw II : Tables and visualization\"\ndate: \"2025-05-11\"\n\nexecute:\n  echo: true\n  eval: false\n  collapse: true\n\nformat:\n  html:\n    output-file: hmw-II.html\n  pdf:\n    output-file: hmw-II.pdf\n\ndraft: false\nprefer-html: true\n\n# engine: jupyter\nengine: knitr\n---\n\n::: {.callout-important}\n\n- Due : May 29, 2025\n- Work in pairs\n- Deliver your work as a `qmd` file through a github {{< fa brands github >}} repository\n- Use the `quarto` package for reproducible research\n- Use `pyspark` or `sparlyr`\n- Use `spark-nlp` for text annotation \n- The report should be rendered at least in HTML format, and possibly also in PDF format\n\n:::\n\n### {{< fa map >}} Objectives\n\nThis homework is an opportunity to use `pyspark`/`sparlyr`/`spark-nlp`.\n\n- Extract/Load/Transform the Balzac corpus\n- Annotate the corpus with `spark-nlp`\n- Perform Stylometric Analysis and Visualize the results using either `plotly` or `altair`\n- Design a way to store results using `parquet` files. Motivate your solution.\n\nCompare annotations from Spark NLP and annotations from Spacy (usability, agreement).  \n\nIn Stylometric analysis, you should at least \n\n- Compute Flesch-Kincaid and Kandel-Moles readability indices and design a visualization\n- Compute *sliding* readability indices over sliding windows defined by \n  different window sizes. How stable are readability indices? \n- Display Zipf plots for the different documents\n- Segment the different texts into *dialog* and *narration* parts.\n\n\nTune your spark session so as to minimize shuffles, use multi-core architectures as much as possible.\n\n{{< fa hand-point-right >}} Your deliverable shall consist in a `qmd` file that can be rendered in HTML format.\n\nYou shall describe the downloaded data.\n\nPlots shall be endowed with titles, legends and captions,\n\nData, NLP  pipelines and graphical pipelines shall be given in an appendix.\n\n### {{< fa database >}} Data\n\n\n\n\n::: {.columns}\n\n::: {.column width=\"60%\"}\n\nData can be downloaded/scrapped from different sources \n\n- <https://github.com/dh-trier/balzac/tree/master>  (not complete)\n- <https://www.gutenberg.org/> (17 volumes of *Comédie humaines*)\n- ...\n\n\n:::\n\n::: {.column width=\"5%\"}\n\n:::\n\n::: {.column width=\"35%\"}\n\n{{< fa hand-point-right >}} Table wrangling should be performed using  `Spark Dataframes` Dataframes.\n\n{{< fa hand-point-right >}} Your extraction (ELT) pipeline shall be *reproducible* and shall be given and motivated in an appendix. \n\nYou are not supposed to deliver the text files as a zipped archive. \n\n{{< fa hand-point-right >}} Annotate with [`soark-nlp`](https://sparknlp.org)\n\n{{< fa hand-point-right >}} Annotation shall be done \non a per novel basis. It should be performed in a parallel (and distributed) way. \n\n{{< fa hand-point-right >}} Graphical pipelines should be reproducible and shall be given in an appendix.\n\n:::\n:::\n\n{{< fa hand-point-right >}} Keep the downloaded data in a separate subdirectory. Your working directory (working tree) should look like something like that:\n\n\n```{.default}\n.\n├── .git/\n├── DATA/\n├──\n|   :\n├── _extensions/\n├── _outdir/\n├── _metadata.yml\n├── _quarto.yml\n├── our_report.qmd\n├── :\n└── README.md\n```\n\n\n\n\n## {{< fa chart-bar >}} Report organization\n\nThe first part  (introduction) of the report shall be dedicated to the description of the data to be extracted and to the extraction pipeline (not different from Homework I). \n\nThe second part of the report shall be dedicated to the description of load/transform pipeline. \n\nThe third part of the report  shall be dedicated  to the description of the annotation pipeline\n\nThe fourth part of the  report shall be dedicated to the stylometric analysis: which questions did you pick up (and why?), plots, summary tables  and comments. Refrain from overplaying your hand: yours plots are not likely to provide a new literary interpretation of Balzac opera. Comment the data, all the data, and nothing but the data.\n\nThe fifth part is the appendix. The first four parts should be mostly text and plots. The fifth part should be code only.\n\nThe appendix shall be dedicated to the details of the pipelines. You shall give the code. \n\nYou shall also give the code of the graphical pipelines in the appendix.\n\nYou shall avoid copy-paste coding. Don't Repeat Yourself. `knitr` provide the tools to organize the Quarto file so that you can write your code once and use it many times, once for data wrangling and plotting (without echoing), then for listing and explanation.\n\n::: {.callout-tip}\n\n### Organizing a report using the `jupyter` engine\n\n:::\n\n## {{< fa book >}} References\n\n- [Data Humanities with R](https://humanitiesdata.org)\n- [Spacy](https://spacy.io)\n- [Spark NLP](https://sparknlp.org)\n- [Web scrapping]()\n- [`scrapy`](https://scrapy.org) \n- [`stylo`](https://github.com/computationalstylistics/stylo)  \n- [`py2r`](https://rpy2.github.io)\n- [Computational stylistics](https://computationalstylistics.github.io)\n\n## Data sources\n\n- [`Project Gutenberg`](https://www.gutenberg.org): you can find the `La Comédie Humaine` using a simple search. All volumes can be downloaded as text files from there.  \n\n## {{< fa graduation-cap >}} Grading criteria\n\n\n\n| Criterion | Points  | Details |\n|:----------|:-------:|:--------|\n|Narrative, spelling and syntax | 20% | English/French {{<  fa pen-fancy >}}|\n|Plots correction | 15% | choice of `aesthetics`, `geom`, `scale` ... {{<  fa chart-area >}}|\n|Plot style | 10% | Titles, legends, labels, breaks ... {{<  fa chart-area >}} |\n|ETL  | 20% | ETL, SQL like manipulations {{<  fa database >}} |\n|Annotation |  10% | Annotations {{<  fa book >}} ||\n|Computing Statistics | 5% |  ... {{<  fa chart-area >}} |\n|DRY compliance | 20% | DRY principle at {{<  fa brands  wikipedia-w  >}} [ Wikipedia ](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself)|\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}